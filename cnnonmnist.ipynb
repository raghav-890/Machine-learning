{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**first implementing basic neural network**","metadata":{}},{"cell_type":"markdown","source":"**--------------------------------------------------------------------------------**","metadata":{}},{"cell_type":"markdown","source":"**importing necessary libraries**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.datasets import mnist","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T20:04:40.842268Z","iopub.execute_input":"2024-11-10T20:04:40.843025Z","iopub.status.idle":"2024-11-10T20:04:52.376272Z","shell.execute_reply.started":"2024-11-10T20:04:40.842985Z","shell.execute_reply":"2024-11-10T20:04:52.375463Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\n\n# Load the MNIST dataset\n#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n# Load the MNIST dataset\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n\n# Normalize the data\nx_train = tf.keras.utils.normalize(x_train, axis=1)\nx_test = tf.keraas.utils.normalize(x_test, axis=1)\n\n# Define the model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28)),                   # Corrected layer spelling and syntax\n    tf.keras.layers.Dense(units=784, activation='relu'),\n    tf.keras.layers.Dense(units=28, activation='relu'),\n    tf.keras.layers.Dense(units=10, activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Corrected 'metrics' spelling\n\n# Train the model\nmodel.fit(x_train, y_train, epochs=3)\n\n# Evaluate the model\nloss, accuracy = model.evaluate(x_test, y_test)\nprint(\"Loss:\", loss, \"Accuracy:\", accuracy)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-04T19:35:48.504158Z","iopub.execute_input":"2024-11-04T19:35:48.504463Z","iopub.status.idle":"2024-11-04T19:36:28.252231Z","shell.execute_reply.started":"2024-11-04T19:35:48.504428Z","shell.execute_reply":"2024-11-04T19:36:28.251316Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730748973.939079      79 service.cc:145] XLA service 0x7d66500053d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730748973.939123      79 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730748973.939127      79 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 102/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5858 - loss: 1.3435","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730748976.160014      79 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.8797 - loss: 0.4060\nEpoch 2/3\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9726 - loss: 0.0897\nEpoch 3/3\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9817 - loss: 0.0577\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9712 - loss: 0.0899\nLoss: 0.07749664038419724 Accuracy: 0.9757999777793884\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"accuracy = 0.9757999777793884","metadata":{}},{"cell_type":"markdown","source":"\n**now implementing CNN**","metadata":{}},{"cell_type":"code","source":"# Load and normalize the data\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nx_train = tf.keras.utils.normalize(x_train, axis=1)\nx_test = tf.keras.utils.normalize(x_test, axis=1)\n\n# Reshape the data to add the channel dimension\nx_train = x_train.reshape(-1, 28, 28, 1)\nx_test = x_test.reshape(-1, 28, 28, 1)\n\n# Define the model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(10, activation='softmax')  # Final dense layer with softmax for classification\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n# Train the model\nmodel.fit(x_train, y_train, epochs=3)\n\n# Evaluate the model\nloss, accuracy = model.evaluate(x_test, y_test)\nprint(\"Loss:\", loss, \"Accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T20:10:29.005987Z","iopub.execute_input":"2024-11-10T20:10:29.006397Z","iopub.status.idle":"2024-11-10T20:10:47.421305Z","shell.execute_reply.started":"2024-11-10T20:10:29.006360Z","shell.execute_reply":"2024-11-10T20:10:47.420365Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1731269432.475472      79 service.cc:145] XLA service 0x7e9638003be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1731269432.475533      79 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1731269432.475547      79 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  84/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2414 - loss: 2.1395","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1731269435.211062      79 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.7123\nEpoch 2/3\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1443\nEpoch 3/3\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.1037\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.1094\nLoss: 0.0925748348236084 Accuracy: 0.9733999967575073\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"accuracy = 0.9733999967575073\n\ndifference from basic NN = -0.002499","metadata":{}},{"cell_type":"markdown","source":"now using from_logits method to reduce round off error","metadata":{}},{"cell_type":"code","source":"# Load and normalize the data\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\nx_train = tf.keras.utils.normalize(x_train, axis=1)\nx_test = tf.keras.utils.normalize(x_test, axis=1)\n\n# Reshape the data to add the channel dimension\nx_train = x_train.reshape(-1, 28, 28, 1)\nx_test = x_test.reshape(-1, 28, 28, 1)\n\n# Define the model\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n    tf.keras.layers.MaxPooling2D((2, 2)),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(10)  # No softmax activation here if using logits\n])\n\n# Compile the model with from_logits=True in the loss function\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n# Train the model\nmodel.fit(x_train, y_train, epochs=3)\n\n# Evaluate the model on x_test and y_test\nloss, accuracy = model.evaluate(x_test, y_test)\nprint(\"Loss:\", loss, \"Accuracy:\", accuracy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T20:12:22.863749Z","iopub.execute_input":"2024-11-10T20:12:22.864642Z","iopub.status.idle":"2024-11-10T20:12:38.984336Z","shell.execute_reply.started":"2024-11-10T20:12:22.864600Z","shell.execute_reply":"2024-11-10T20:12:38.983512Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.6970\nEpoch 2/3\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.1233\nEpoch 3/3\n\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9718 - loss: 0.0929\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.0974\nLoss: 0.08033879101276398 Accuracy: 0.9754999876022339\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":" accuracy = 0.9754999876022339\n\n difference from basic NN = +0.0003","metadata":{}},{"cell_type":"markdown","source":"**making optimizations to CNN**\n\n1. introducing batch normalization layer(for normalization) in between the conv2d layers\n2. introducing dropout layer after batch normalization to regularize","metadata":{}},{"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize to [0,1] range\nx_train = x_train[..., tf.newaxis]  # Add channel dimension\nx_test = x_test[..., tf.newaxis]\n# Define the CNN model\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n    layers.BatchNormalization(),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    layers.Dropout(0.25),\n\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    layers.Dropout(0.25),\n\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(10)  # No activation here, using logits\n])\n\n# Compile the model with from_logits=True\nmodel.compile(optimizer=Adam(),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n# Train the model\nhistory = model.fit(x_train, y_train, epochs=20, batch_size=128,\n                    validation_data=(x_test, y_test) )\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(x_test, y_test)\nprint(\"Test accuracy:\", test_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T11:37:24.059853Z","iopub.execute_input":"2024-11-06T11:37:24.060758Z","iopub.status.idle":"2024-11-06T11:39:02.550631Z","shell.execute_reply.started":"2024-11-06T11:37:24.060718Z","shell.execute_reply":"2024-11-06T11:39:02.549815Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 21ms/step - accuracy: 0.8925 - loss: 0.3597 - val_accuracy: 0.6953 - val_loss: 0.8652\nEpoch 2/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9802 - loss: 0.0650 - val_accuracy: 0.9896 - val_loss: 0.0310\nEpoch 3/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9861 - loss: 0.0449 - val_accuracy: 0.9904 - val_loss: 0.0272\nEpoch 4/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9883 - loss: 0.0380 - val_accuracy: 0.9936 - val_loss: 0.0212\nEpoch 5/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0332 - val_accuracy: 0.9931 - val_loss: 0.0210\nEpoch 6/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0263 - val_accuracy: 0.9909 - val_loss: 0.0252\nEpoch 7/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9925 - loss: 0.0253 - val_accuracy: 0.9930 - val_loss: 0.0212\nEpoch 8/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0214 - val_accuracy: 0.9923 - val_loss: 0.0239\nEpoch 9/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0209 - val_accuracy: 0.9934 - val_loss: 0.0191\nEpoch 10/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9934 - loss: 0.0213 - val_accuracy: 0.9934 - val_loss: 0.0184\nEpoch 11/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9942 - loss: 0.0188 - val_accuracy: 0.9941 - val_loss: 0.0167\nEpoch 12/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0162 - val_accuracy: 0.9945 - val_loss: 0.0158\nEpoch 13/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9948 - loss: 0.0165 - val_accuracy: 0.9939 - val_loss: 0.0180\nEpoch 14/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9948 - loss: 0.0154 - val_accuracy: 0.9940 - val_loss: 0.0176\nEpoch 15/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.0152 - val_accuracy: 0.9941 - val_loss: 0.0179\nEpoch 16/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9957 - loss: 0.0129 - val_accuracy: 0.9939 - val_loss: 0.0187\nEpoch 17/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0113 - val_accuracy: 0.9953 - val_loss: 0.0176\nEpoch 18/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9959 - loss: 0.0118 - val_accuracy: 0.9942 - val_loss: 0.0202\nEpoch 19/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9964 - loss: 0.0107 - val_accuracy: 0.9949 - val_loss: 0.0179\nEpoch 20/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0098 - val_accuracy: 0.9945 - val_loss: 0.0195\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0226\nTest accuracy: 0.9944999814033508\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"accuracy = 0.9944999814033508\n\ndifference from basic NN = +0.018","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T11:05:07.093918Z","iopub.execute_input":"2024-11-06T11:05:07.094403Z","iopub.status.idle":"2024-11-06T11:05:21.919431Z","shell.execute_reply.started":"2024-11-06T11:05:07.094347Z","shell.execute_reply":"2024-11-06T11:05:21.918653Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**further optimization**\n\nadding reduceLRonplateau \nname is self explanatory, it reduces the learning rate once there is no further improvement in the criteria(we decide the criteria)\nit waits for a certain number of iterations on plateau(also decided by us)\nwe can set a minimum value of LR, below which it will not go","metadata":{}},{"cell_type":"code","source":"# Load and preprocess the data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\nx_train, x_test = x_train / 255.0, x_test / 255.0  # Normalize to [0,1] range\nx_train = x_train[..., tf.newaxis]  # Add channel dimension\nx_test = x_test[..., tf.newaxis]\n\n# Define the CNN model\nmodel = models.Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n    layers.BatchNormalization(),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    layers.Dropout(0.25),\n\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D((2, 2)),\n    layers.Dropout(0.25),\n\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.5),\n    layers.Dense(10)  # No activation here, using logits\n])\n\n# Compile the model with from_logits=True\nmodel.compile(optimizer=Adam(),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n# Learning rate scheduler\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5, verbose=1)\n\n# Train the model\nhistory = model.fit(x_train, y_train, epochs=20, batch_size=128,\n                    validation_data=(x_test, y_test), callbacks=[lr_scheduler])\n\n# Evaluate the model\ntest_loss, test_acc = model.evaluate(x_test, y_test)\nprint(\"Test accuracy:\", test_acc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T11:05:33.187121Z","iopub.execute_input":"2024-11-06T11:05:33.187715Z","iopub.status.idle":"2024-11-06T11:07:14.811439Z","shell.execute_reply.started":"2024-11-06T11:05:33.187681Z","shell.execute_reply":"2024-11-06T11:07:14.810469Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1730891138.167482      77 service.cc:145] XLA service 0x7960e8006e20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1730891138.167545      77 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1730891138.167550      77 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 16/469\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.4538 - loss: 1.9473  ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1730891146.058559      77 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 24ms/step - accuracy: 0.8910 - loss: 0.3706 - val_accuracy: 0.8164 - val_loss: 0.5305 - learning_rate: 0.0010\nEpoch 2/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9797 - loss: 0.0651 - val_accuracy: 0.9848 - val_loss: 0.0448 - learning_rate: 0.0010\nEpoch 3/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9852 - loss: 0.0468 - val_accuracy: 0.9903 - val_loss: 0.0291 - learning_rate: 0.0010\nEpoch 4/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0385 - val_accuracy: 0.9904 - val_loss: 0.0289 - learning_rate: 0.0010\nEpoch 5/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9895 - loss: 0.0328 - val_accuracy: 0.9930 - val_loss: 0.0225 - learning_rate: 0.0010\nEpoch 6/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0279 - val_accuracy: 0.9925 - val_loss: 0.0256 - learning_rate: 0.0010\nEpoch 7/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9921 - loss: 0.0261 - val_accuracy: 0.9933 - val_loss: 0.0201 - learning_rate: 0.0010\nEpoch 8/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9930 - loss: 0.0239 - val_accuracy: 0.9943 - val_loss: 0.0213 - learning_rate: 0.0010\nEpoch 9/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9936 - loss: 0.0207 - val_accuracy: 0.9949 - val_loss: 0.0161 - learning_rate: 0.0010\nEpoch 10/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0213 - val_accuracy: 0.9938 - val_loss: 0.0188 - learning_rate: 0.0010\nEpoch 11/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9941 - loss: 0.0175 - val_accuracy: 0.9929 - val_loss: 0.0231 - learning_rate: 0.0010\nEpoch 12/20\n\u001b[1m463/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0200\nEpoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0200 - val_accuracy: 0.9933 - val_loss: 0.0203 - learning_rate: 0.0010\nEpoch 13/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0135 - val_accuracy: 0.9937 - val_loss: 0.0192 - learning_rate: 5.0000e-04\nEpoch 14/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.9944 - val_loss: 0.0167 - learning_rate: 5.0000e-04\nEpoch 15/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0101\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.9940 - val_loss: 0.0181 - learning_rate: 5.0000e-04\nEpoch 16/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9973 - loss: 0.0077 - val_accuracy: 0.9945 - val_loss: 0.0161 - learning_rate: 2.5000e-04\nEpoch 17/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9956 - val_loss: 0.0159 - learning_rate: 2.5000e-04\nEpoch 18/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9948 - val_loss: 0.0172 - learning_rate: 2.5000e-04\nEpoch 19/20\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9952 - val_loss: 0.0172 - learning_rate: 2.5000e-04\nEpoch 20/20\n\u001b[1m463/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9983 - loss: 0.0052\nEpoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.9948 - val_loss: 0.0170 - learning_rate: 2.5000e-04\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 0.0194\nTest accuracy: 0.9947999715805054\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"accuracy = 0.9947999715805054\n\ndifference from basic NN = +0.019","metadata":{}},{"cell_type":"markdown","source":"**making more optimizations**\nintroducing data augmentation \nits basically feeding the model a slight variation of the data(ex- zoomed in)\n\nwe use tensorflow's ImageDataGenerator to implement it\nit has useful arguments such as rotation_image, zoom_range etc.\n\nthen we fit the model to the data, for that we use .flow() method\nusing this we can feed the data in small batches, so data in trained on variety\nvalidation_data is x_test & y_test","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T20:32:57.753323Z","iopub.execute_input":"2024-11-10T20:32:57.753805Z","iopub.status.idle":"2024-11-10T20:32:57.764084Z","shell.execute_reply.started":"2024-11-10T20:32:57.753758Z","shell.execute_reply":"2024-11-10T20:32:57.763016Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Load data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Normalize pixel values to be between 0 and 1\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# Reshape data to include a single channel (grayscale)\nx_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\nx_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n\n# One-hot encode labels\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\n\n\n#data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=10,       # Random rotation\n    zoom_range=0.1,          # Random zoom\n    width_shift_range=0.1,   # Horizontal shift\n    height_shift_range=0.1   # Vertical shift\n)\n\ndatagen.fit(x_train)\n\nmodel = models.Sequential()\n\n# First convolutional block\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\n\n# Second convolutional block\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\n\n# Fully connected layer\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(10, activation='softmax'))\n\n#compiling the model\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\n# Train the model with augmented data\nhistory = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n                    epochs=15, validation_data=(x_test, y_test))\n\n#test the trained model\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test accuracy: {test_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T20:34:22.885146Z","iopub.execute_input":"2024-11-10T20:34:22.885526Z","iopub.status.idle":"2024-11-10T20:39:58.067955Z","shell.execute_reply.started":"2024-11-10T20:34:22.885493Z","shell.execute_reply":"2024-11-10T20:39:58.066991Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8037 - loss: 0.6527 - val_accuracy: 0.9826 - val_loss: 0.0506\nEpoch 2/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9599 - loss: 0.1273 - val_accuracy: 0.9894 - val_loss: 0.0313\nEpoch 3/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9737 - loss: 0.0843 - val_accuracy: 0.9899 - val_loss: 0.0333\nEpoch 4/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9782 - loss: 0.0712 - val_accuracy: 0.9944 - val_loss: 0.0170\nEpoch 5/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9808 - loss: 0.0645 - val_accuracy: 0.9926 - val_loss: 0.0208\nEpoch 6/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9813 - loss: 0.0599 - val_accuracy: 0.9928 - val_loss: 0.0197\nEpoch 7/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9838 - loss: 0.0535 - val_accuracy: 0.9932 - val_loss: 0.0197\nEpoch 8/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9842 - loss: 0.0524 - val_accuracy: 0.9956 - val_loss: 0.0142\nEpoch 9/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9869 - loss: 0.0432 - val_accuracy: 0.9922 - val_loss: 0.0206\nEpoch 10/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9853 - loss: 0.0475 - val_accuracy: 0.9932 - val_loss: 0.0216\nEpoch 11/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9876 - loss: 0.0391 - val_accuracy: 0.9948 - val_loss: 0.0159\nEpoch 12/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9876 - loss: 0.0397 - val_accuracy: 0.9955 - val_loss: 0.0143\nEpoch 13/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9876 - loss: 0.0413 - val_accuracy: 0.9953 - val_loss: 0.0130\nEpoch 14/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9877 - loss: 0.0384 - val_accuracy: 0.9950 - val_loss: 0.0160\nEpoch 15/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9891 - loss: 0.0352 - val_accuracy: 0.9956 - val_loss: 0.0141\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9948 - loss: 0.0164\nTest accuracy: 0.9955999851226807\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"accuracy = 0.995599851\n\ndifference from basic NN = +0.02","metadata":{}},{"cell_type":"code","source":"# Load data\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Normalize pixel values to be between 0 and 1\nx_train, x_test = x_train / 255.0, x_test / 255.0\n\n# Reshape data to include a single channel (grayscale)\nx_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\nx_test = x_test.reshape((x_test.shape[0], 28, 28, 1))\n\n# One-hot encode labels\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\n\n\n#data augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=10,       # Random rotation\n    zoom_range=0.1,          # Random zoom\n    width_shift_range=0.1,   # Horizontal shift\n    height_shift_range=0.1   # Vertical shift\n)\n\ndatagen.fit(x_train)\n\nmodel = models.Sequential()\n\n# First convolutional block\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\n\n# Second convolutional block\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPooling2D((2, 2)))\nmodel.add(layers.Dropout(0.25))\n\n# Fully connected layer\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(10, activation='softmax'))\n\n# Learning rate scheduler\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5, verbose=1)\n\n#compiling the model\nmodel.compile(optimizer='adam',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n\n# Train the model with augmented data\nhistory = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n                    epochs=15, validation_data=(x_test, y_test), callbacks=[lr_scheduler])\n\n#test the trained model\ntest_loss, test_accuracy = model.evaluate(x_test, y_test)\nprint(f\"Test accuracy: {test_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-10T21:00:43.041618Z","iopub.execute_input":"2024-11-10T21:00:43.042031Z","iopub.status.idle":"2024-11-10T21:06:15.776039Z","shell.execute_reply.started":"2024-11-10T21:00:43.041993Z","shell.execute_reply":"2024-11-10T21:06:15.775105Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 29ms/step - accuracy: 0.7998 - loss: 0.6523 - val_accuracy: 0.9870 - val_loss: 0.0394 - learning_rate: 0.0010\nEpoch 2/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.9641 - loss: 0.1175 - val_accuracy: 0.9916 - val_loss: 0.0285 - learning_rate: 0.0010\nEpoch 3/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9728 - loss: 0.0893 - val_accuracy: 0.9863 - val_loss: 0.0430 - learning_rate: 0.0010\nEpoch 4/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9771 - loss: 0.0763 - val_accuracy: 0.9917 - val_loss: 0.0291 - learning_rate: 0.0010\nEpoch 5/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9803 - loss: 0.0682 - val_accuracy: 0.9928 - val_loss: 0.0214 - learning_rate: 0.0010\nEpoch 6/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.9814 - loss: 0.0604 - val_accuracy: 0.9909 - val_loss: 0.0283 - learning_rate: 0.0010\nEpoch 7/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9841 - loss: 0.0534 - val_accuracy: 0.9950 - val_loss: 0.0148 - learning_rate: 0.0010\nEpoch 8/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9844 - loss: 0.0507 - val_accuracy: 0.9950 - val_loss: 0.0157 - learning_rate: 0.0010\nEpoch 9/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9861 - loss: 0.0458 - val_accuracy: 0.9945 - val_loss: 0.0147 - learning_rate: 0.0010\nEpoch 10/15\n\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9869 - loss: 0.0451\nEpoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9869 - loss: 0.0451 - val_accuracy: 0.9938 - val_loss: 0.0194 - learning_rate: 0.0010\nEpoch 11/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9887 - loss: 0.0383 - val_accuracy: 0.9933 - val_loss: 0.0213 - learning_rate: 5.0000e-04\nEpoch 12/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9891 - loss: 0.0353 - val_accuracy: 0.9955 - val_loss: 0.0131 - learning_rate: 5.0000e-04\nEpoch 13/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9905 - loss: 0.0316 - val_accuracy: 0.9949 - val_loss: 0.0141 - learning_rate: 5.0000e-04\nEpoch 14/15\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9911 - loss: 0.0299 - val_accuracy: 0.9951 - val_loss: 0.0148 - learning_rate: 5.0000e-04\nEpoch 15/15\n\u001b[1m933/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9913 - loss: 0.0292\nEpoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.9912 - loss: 0.0293 - val_accuracy: 0.9953 - val_loss: 0.0141 - learning_rate: 5.0000e-04\n\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0153\nTest accuracy: 0.9952999949455261\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"accuracy = 0.995299\n\ndifference from basic NN = +0.02","metadata":{}}]}